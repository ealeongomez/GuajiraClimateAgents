{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header-cell",
      "metadata": {},
      "source": [
        "#  **RAG with ChromaDB**\n",
        "\n",
        "> **Project:** GuajiraClimateAgents  \n",
        "> **Author:** Eder Arley Le√≥n G√≥mez  \n",
        "> **GitHub:** https://github.com/ealeongomez  \n",
        "> **License:** MIT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "env-check-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path().resolve().parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Paths importantes\n",
        "PDF_PATH = PROJECT_ROOT / \"data\" / \"pdfs\" / \"4349.pdf\"\n",
        "EMBEDDINGS_PATH = PROJECT_ROOT / \"data\" / \"embeddings\"\n",
        "\n",
        "load_dotenv(PROJECT_ROOT / \".env\")\n",
        "\n",
        "# Verificar que las API keys est√©n configuradas\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79107c4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.vector_store import VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-pdf-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el PDF\n",
        "loader = PyPDFLoader(str(PDF_PATH))\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# Dividir los documentos\n",
        "chunks = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vectorstore-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\"  # Modelo m√°s econ√≥mico y eficiente\n",
        ")\n",
        "\n",
        "vector_store = VectorStore(collection_name=\"Atlas_eolico_Colombia\", embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add-docs-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "ids = vector_store.add_documents(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "search-basic-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo de b√∫squeda b√°sica\n",
        "query = \"¬øCu√°l es el tema principal del documento?\"\n",
        "\n",
        "results = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Resultado {i} ---\")\n",
        "    print(f\"üìÑ P√°gina: {doc.metadata.get('page', 'N/A')}\")\n",
        "    print(f\"üìù Contenido:\\n{doc.page_content[:400]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "search-score-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# B√∫squeda con scores de similitud\n",
        "query = \"clima\"\n",
        "\n",
        "results_with_scores = vector_store.similarity_search_with_score(query, k=5)\n",
        "\n",
        "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
        "    print(f\"\\n--- Resultado {i} (Score: {score:.4f}) ---\")\n",
        "    print(f\"üìÑ P√°gina: {doc.metadata.get('page', 'N/A')}\")\n",
        "    print(f\"üìù Contenido:\\n{doc.page_content[:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rag-header",
      "metadata": {},
      "source": [
        "## 6. Ejemplo de RAG completo\n",
        "\n",
        "Combinamos la b√∫squeda vectorial con un LLM para responder preguntas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rag-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar el LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Crear el retriever\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Template para RAG\n",
        "template = \"\"\"Responde la pregunta bas√°ndote √∫nicamente en el siguiente contexto:\n",
        "\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Crear la cadena RAG\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Cadena RAG configurada correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rag-query-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hacer una pregunta usando RAG\n",
        "question = \"¬øCu√°l es el tema principal del documento?\"\n",
        "\n",
        "print(f\"‚ùì Pregunta: {question}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\\nüí¨ Respuesta:\")\n",
        "\n",
        "response = rag_chain.invoke(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interactive-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda interactiva para hacer m√°s preguntas\n",
        "# Modifica la variable 'pregunta' y ejecuta esta celda\n",
        "\n",
        "pregunta = \"Escribe aqu√≠ tu pregunta sobre el documento\"\n",
        "\n",
        "print(f\"‚ùì {pregunta}\")\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "respuesta = rag_chain.invoke(pregunta)\n",
        "print(f\"\\nüí¨ {respuesta}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
